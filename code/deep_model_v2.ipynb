{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9c9e3a",
   "metadata": {},
   "source": [
    "# V2 - Clean Code Development of Deep Model - with Adversarial Training\n",
    "This is a *supremely* tidied up version of my earlier code-files to develop the Deep Learning Model.\n",
    "\n",
    "This came as a result of learning to use:\n",
    "1. **Torch**: Lack of prior experience! Big learning curve, but this is a fascinatingly nuanced library. Over time, I recognized & modularized re-used code into functions.\n",
    "2. **wandb**: Intuitive but a learning curve too - the wandb project for these models is very messy!\n",
    "3. **DL Concepts**: Earlier methods used only stratified validation methods and **NO** user embedding/adversarial training methods -- after understanding these concepts and learning how they should be implemented, i copied much of the previous code into this file & developed further.\n",
    "\n",
    "\n",
    "This notebook is as used within Google Colab, to take advantage of torch.cuda() and the T4 GPU runtimes.\n",
    "For simplification, I've distilled everything into 1 code-block, but the contents are as follows:\n",
    "\n",
    "1. **Imports/Initialisations** (wandb, random_state seeds)\n",
    "2. **Functions** for:\n",
    "    1. Preparing the data as torch.Tensor's (user_ids, X, y) \n",
    "    2. Methods for the model: AdversarialGradReverse (returning $-\\lambda\\times L$ (Loss) to *confuse*/lower the accuracy of user-prediction - Adversarial Training!), Normalization automations, \n",
    "    3. WANDB automations\n",
    "3. **The Model**: NewModel(nn.Module) - built from feature_extraction and user_embeds in .forward() for domain-adaptable predictive capacity\n",
    "4. **Training Functions** (train-test split, confusion matrix, predictions on test-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53df23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">HAR_user_adversarial</strong> at: <a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model/runs/xasna8pb' target=\"_blank\">https://wandb.ai/dafjames99-ml/wisdm_deep_model/runs/xasna8pb</a><br> View project at: <a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model' target=\"_blank\">https://wandb.ai/dafjames99-ml/wisdm_deep_model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_190531-xasna8pb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/main.py:308: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dafyddthomas/Documents/Code/python_projects/WISDM_project/wandb/run-20250508_202551-mxqraxjj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model/runs/mxqraxjj' target=\"_blank\">HAR_user_adversarial</a></strong> to <a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model' target=\"_blank\">https://wandb.ai/dafjames99-ml/wisdm_deep_model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model/runs/mxqraxjj' target=\"_blank\">https://wandb.ai/dafjames99-ml/wisdm_deep_model/runs/mxqraxjj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 4.1319, Val Loss = 4.1508\n",
      "  Activity Acc = 0.4084, User Acc = 0.0800 (lower is better)\n",
      "  Precision = 0.4193, Recall = 0.4084, F1 Score = 0.3752\n",
      "  Alpha = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 3.4481, Val Loss = 3.7753\n",
      "  Activity Acc = 0.5054, User Acc = 0.0776 (lower is better)\n",
      "  Precision = 0.5002, Recall = 0.5054, F1 Score = 0.4610\n",
      "  Alpha = 0.0667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 3.3969, Val Loss = 3.7840\n",
      "  Activity Acc = 0.5070, User Acc = 0.0893 (lower is better)\n",
      "  Precision = 0.4681, Recall = 0.5070, F1 Score = 0.4635\n",
      "  Alpha = 0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 3.3202, Val Loss = 3.6935\n",
      "  Activity Acc = 0.5435, User Acc = 0.0947 (lower is better)\n",
      "  Precision = 0.4844, Recall = 0.5435, F1 Score = 0.4944\n",
      "  Alpha = 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 3.2788, Val Loss = 3.7338\n",
      "  Activity Acc = 0.5357, User Acc = 0.0846 (lower is better)\n",
      "  Precision = 0.4663, Recall = 0.5357, F1 Score = 0.4826\n",
      "  Alpha = 0.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 3.2786, Val Loss = 3.7393\n",
      "  Activity Acc = 0.5404, User Acc = 0.0753 (lower is better)\n",
      "  Precision = 0.4878, Recall = 0.5404, F1 Score = 0.4867\n",
      "  Alpha = 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 3.2865, Val Loss = 3.7659\n",
      "  Activity Acc = 0.5295, User Acc = 0.0668 (lower is better)\n",
      "  Precision = 0.4789, Recall = 0.5295, F1 Score = 0.4813\n",
      "  Alpha = 0.4000\n",
      "Epoch 7: Train Loss = 3.2893, Val Loss = 3.7181\n",
      "  Activity Acc = 0.5334, User Acc = 0.0714 (lower is better)\n",
      "  Precision = 0.8655, Recall = 0.5334, F1 Score = 0.4936\n",
      "  Alpha = 0.4667\n",
      "Epoch 8: Train Loss = 3.2667, Val Loss = 3.6454\n",
      "  Activity Acc = 0.8005, User Acc = 0.0722 (lower is better)\n",
      "  Precision = 0.8466, Recall = 0.8005, F1 Score = 0.8127\n",
      "  Alpha = 0.5333\n",
      "Epoch 9: Train Loss = 3.2447, Val Loss = 3.5908\n",
      "  Activity Acc = 0.8067, User Acc = 0.0745 (lower is better)\n",
      "  Precision = 0.8888, Recall = 0.8067, F1 Score = 0.8216\n",
      "  Alpha = 0.6000\n",
      "Epoch 10: Train Loss = 3.2881, Val Loss = 3.5914\n",
      "  Activity Acc = 0.8043, User Acc = 0.0675 (lower is better)\n",
      "  Precision = 0.8852, Recall = 0.8043, F1 Score = 0.8154\n",
      "  Alpha = 0.6667\n",
      "Epoch 11: Train Loss = 3.2892, Val Loss = 3.6616\n",
      "  Activity Acc = 0.7554, User Acc = 0.0738 (lower is better)\n",
      "  Precision = 0.8418, Recall = 0.7554, F1 Score = 0.7675\n",
      "  Alpha = 0.7333\n",
      "Epoch 12: Train Loss = 3.2659, Val Loss = 3.5786\n",
      "  Activity Acc = 0.8525, User Acc = 0.0831 (lower is better)\n",
      "  Precision = 0.8826, Recall = 0.8525, F1 Score = 0.8560\n",
      "  Alpha = 0.8000\n",
      "Epoch 13: Train Loss = 3.2834, Val Loss = 3.5006\n",
      "  Activity Acc = 0.8354, User Acc = 0.0854 (lower is better)\n",
      "  Precision = 0.8926, Recall = 0.8354, F1 Score = 0.8496\n",
      "  Alpha = 0.8667\n",
      "Epoch 14: Train Loss = 3.2363, Val Loss = 3.4583\n",
      "  Activity Acc = 0.8571, User Acc = 0.0745 (lower is better)\n",
      "  Precision = 0.9022, Recall = 0.8571, F1 Score = 0.8644\n",
      "  Alpha = 0.9333\n",
      "Epoch 15: Train Loss = 3.2327, Val Loss = 3.4650\n",
      "  Activity Acc = 0.8859, User Acc = 0.0986 (lower is better)\n",
      "  Precision = 0.9170, Recall = 0.8859, F1 Score = 0.8930\n",
      "  Alpha = 1.0000\n",
      "Epoch 16: Train Loss = 3.1821, Val Loss = 3.4538\n",
      "  Activity Acc = 0.9130, User Acc = 0.0753 (lower is better)\n",
      "  Precision = 0.9259, Recall = 0.9130, F1 Score = 0.9167\n",
      "  Alpha = 1.0000\n",
      "Epoch 17: Train Loss = 3.1717, Val Loss = 3.7999\n",
      "  Activity Acc = 0.6894, User Acc = 0.0784 (lower is better)\n",
      "  Precision = 0.8358, Recall = 0.6894, F1 Score = 0.7063\n",
      "  Alpha = 1.0000\n",
      "Epoch 18: Train Loss = 3.2274, Val Loss = 3.5502\n",
      "  Activity Acc = 0.8773, User Acc = 0.0691 (lower is better)\n",
      "  Precision = 0.9164, Recall = 0.8773, F1 Score = 0.8858\n",
      "  Alpha = 1.0000\n",
      "Epoch 19: Train Loss = 3.1689, Val Loss = 3.3992\n",
      "  Activity Acc = 0.9394, User Acc = 0.0683 (lower is better)\n",
      "  Precision = 0.9464, Recall = 0.9394, F1 Score = 0.9412\n",
      "  Alpha = 1.0000\n",
      "Epoch 20: Train Loss = 3.1921, Val Loss = 3.5148\n",
      "  Activity Acc = 0.9177, User Acc = 0.0753 (lower is better)\n",
      "  Precision = 0.9399, Recall = 0.9177, F1 Score = 0.9222\n",
      "  Alpha = 1.0000\n",
      "Epoch 21: Train Loss = 3.1302, Val Loss = 3.4509\n",
      "  Activity Acc = 0.8859, User Acc = 0.0877 (lower is better)\n",
      "  Precision = 0.9170, Recall = 0.8859, F1 Score = 0.8922\n",
      "  Alpha = 1.0000\n",
      "Epoch 22: Train Loss = 3.1679, Val Loss = 3.3165\n",
      "  Activity Acc = 0.9293, User Acc = 0.0823 (lower is better)\n",
      "  Precision = 0.9405, Recall = 0.9293, F1 Score = 0.9320\n",
      "  Alpha = 1.0000\n",
      "Epoch 23: Train Loss = 3.1607, Val Loss = 3.3364\n",
      "  Activity Acc = 0.9301, User Acc = 0.0691 (lower is better)\n",
      "  Precision = 0.9431, Recall = 0.9301, F1 Score = 0.9327\n",
      "  Alpha = 1.0000\n",
      "Epoch 24: Train Loss = 3.1374, Val Loss = 3.4180\n",
      "  Activity Acc = 0.8967, User Acc = 0.0776 (lower is better)\n",
      "  Precision = 0.9325, Recall = 0.8967, F1 Score = 0.9044\n",
      "  Alpha = 1.0000\n",
      "Epoch 25: Train Loss = 3.1412, Val Loss = 3.3336\n",
      "  Activity Acc = 0.9317, User Acc = 0.0668 (lower is better)\n",
      "  Precision = 0.9443, Recall = 0.9317, F1 Score = 0.9340\n",
      "  Alpha = 1.0000\n",
      "Epoch 26: Train Loss = 3.1577, Val Loss = 3.3794\n",
      "  Activity Acc = 0.9247, User Acc = 0.0815 (lower is better)\n",
      "  Precision = 0.9358, Recall = 0.9247, F1 Score = 0.9270\n",
      "  Alpha = 1.0000\n",
      "Epoch 27: Train Loss = 3.1241, Val Loss = 3.3194\n",
      "  Activity Acc = 0.9356, User Acc = 0.0730 (lower is better)\n",
      "  Precision = 0.9452, Recall = 0.9356, F1 Score = 0.9378\n",
      "  Alpha = 1.0000\n",
      "Epoch 28: Train Loss = 3.1455, Val Loss = 3.3644\n",
      "  Activity Acc = 0.9084, User Acc = 0.0722 (lower is better)\n",
      "  Precision = 0.9280, Recall = 0.9084, F1 Score = 0.9114\n",
      "  Alpha = 1.0000\n",
      "Epoch 29: Train Loss = 3.1259, Val Loss = 3.4378\n",
      "  Activity Acc = 0.9115, User Acc = 0.0668 (lower is better)\n",
      "  Precision = 0.9289, Recall = 0.9115, F1 Score = 0.9158\n",
      "  Alpha = 1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>activity_accuracy</td><td>▁▂▂▃▃▃▃▃▆▆▆▆▇▇▇▇█▅▇██▇██▇█████</td></tr><tr><td>alpha</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch_time</td><td>▃▄▂▂▁▂▁▂▁▁▁▁▁▁▁█▃▃▃▃▃▅▃▄▄▆▃▂▂▃</td></tr><tr><td>f1_score</td><td>▁▂▂▂▂▂▂▂▆▇▆▆▇▇▇▇█▅▇██▇████████</td></tr><tr><td>precision</td><td>▁▂▂▂▂▂▂▇▇▇▇▇▇▇▇██▇████████████</td></tr><tr><td>recall</td><td>▁▂▂▃▃▃▃▃▆▆▆▆▇▇▇▇█▅▇██▇██▇█████</td></tr><tr><td>train_activity_loss</td><td>█▄▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_user_loss</td><td>█▄▃▁▁▂▂▃▂▂▃▃▃▄▃▄▃▄▅▄▄▄▄▄▄▄▄▄▄▃</td></tr><tr><td>user_accuracy</td><td>▄▃▆▇▅▃▁▂▂▃▁▃▅▅▃█▃▄▂▁▃▆▄▂▃▁▄▂▂▁</td></tr><tr><td>val_activity_loss</td><td>█▅▆▅▅▅▅▄▄▄▃▄▃▃▂▂▂▅▃▁▂▂▁▁▂▁▁▁▁▂</td></tr><tr><td>val_loss</td><td>█▅▅▄▅▅▅▄▄▃▃▄▃▃▂▂▂▅▃▂▃▂▁▁▂▁▂▁▁▂</td></tr><tr><td>val_user_loss</td><td>▇▄▂▁▁▃▄▅▄▃▅▃▄▄▅▆▅▆█▇▇▇▄▄▆▄▆▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>activity_accuracy</td><td>0.91149</td></tr><tr><td>alpha</td><td>1</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>epoch_time</td><td>6.59713</td></tr><tr><td>f1_score</td><td>0.91576</td></tr><tr><td>precision</td><td>0.92891</td></tr><tr><td>recall</td><td>0.91149</td></tr><tr><td>train_activity_loss</td><td>0.15318</td></tr><tr><td>train_loss</td><td>3.12594</td></tr><tr><td>train_user_loss</td><td>2.97276</td></tr><tr><td>user_accuracy</td><td>0.06677</td></tr><tr><td>val_activity_loss</td><td>0.2693</td></tr><tr><td>val_loss</td><td>3.43779</td></tr><tr><td>val_user_loss</td><td>3.16849</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">HAR_user_adversarial</strong> at: <a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model/runs/mxqraxjj' target=\"_blank\">https://wandb.ai/dafjames99-ml/wisdm_deep_model/runs/mxqraxjj</a><br> View project at: <a href='https://wandb.ai/dafjames99-ml/wisdm_deep_model' target=\"_blank\">https://wandb.ai/dafjames99-ml/wisdm_deep_model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_202551-mxqraxjj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path = '/path/to/my/data/dir'\n",
    "predictions_path = '/path/to/my/predictions/dir'\n",
    "\n",
    "df_train = pd.read_csv(path + '/train_signal_clean.csv', converters={'x': json.loads, 'y': json.loads, 'z': json.loads})\n",
    "df_test = pd.read_csv(path + '/test_signal_clean.csv', converters={'x': json.loads, 'y': json.loads, 'z': json.loads})\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module, Linear, Conv1d, MaxPool1d, ReLU, LSTM, CrossEntropyLoss, functional as F, Sequential, Embedding\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, WeightedRandomSampler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "try:\n",
    "  import wandb\n",
    "except:\n",
    "  !pip install wandb\n",
    "  import wandb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "WANDB_ENTITY = 'my_wandb_entity' # Sensitive - replaced with generic values\n",
    "WANDB_PROJECT = 'my_wandb_project' # Sensitive - replaced with generic values\n",
    "\n",
    "MY_SEED = 6\n",
    "\n",
    "torch.manual_seed(MY_SEED)\n",
    "def get_X_signal(df_signal):\n",
    "    X = np.zeros((len(df_signal), 160, 3))\n",
    "    for i in range(len(df_signal)):\n",
    "        X[i, :, :] = np.array([\n",
    "            df_signal['x'].iloc[i], \n",
    "            df_signal['y'].iloc[i], \n",
    "            df_signal['z'].iloc[i], \n",
    "        ]).transpose()\n",
    "    return torch.tensor(X, dtype = torch.float32)\n",
    "\n",
    "def extract_user_ids(df_signal):\n",
    "    user_strings = df_signal['user'].values\n",
    "    user_ids = np.array([int(u.split('_')[1]) for u in user_strings])\n",
    "    return torch.tensor(user_ids, dtype=torch.long)\n",
    "\n",
    "def plot_signal(row, title = None, test = False, seperate_ax = False):\n",
    "    if seperate_ax:\n",
    "        fig, axs = plt.subplots(nrows = 3, ncols = 1, figsize = (13, 10), layout = 'constrained')\n",
    "        axs.ravel()\n",
    "        for ax, c in zip(axs, ['x', 'y', 'z']):\n",
    "            y = row[c]\n",
    "            ax.plot(y, label = c)\n",
    "        plt.legend(bbox_to_anchor = [1, 1])\n",
    "        if title is None:\n",
    "            if not test:\n",
    "                title = row['id'] + ': ' + row['activity']\n",
    "            else:\n",
    "                title = row['id']\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize = (13, 3), layout = 'constrained')\n",
    "            \n",
    "        for c in ['x', 'y', 'z']:\n",
    "            y = row[c]\n",
    "            ax.plot(y, label = c)\n",
    "        plt.legend(bbox_to_anchor = [1, 1])\n",
    "        if title is None:\n",
    "            if not test:\n",
    "                title = row['id'] + ': ' + row['activity']\n",
    "            else:\n",
    "                title = row['id']\n",
    "        plt.suptitle(title)\n",
    "        plt.show()\n",
    "        \n",
    "def get_mean_std(X: Tensor, dims = (0, 1), device = device) -> tuple:\n",
    "    return X.mean(dim = dims).to(device), X.std(dim = dims).to(device)\n",
    "\n",
    "def normalize_X(X: Tensor, mean_std: tuple = None, dims = (0, 1)) -> Tensor:\n",
    "    if mean_std == (None, None):\n",
    "        return X\n",
    "    if mean_std is None:\n",
    "        mean_std = get_mean_std(X, dims = dims)\n",
    "    \n",
    "    return (X - mean_std[0]) / mean_std[1]\n",
    "\n",
    "def extract_model_config(model: Module) -> dict:\n",
    "    config = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if name == \"\":\n",
    "            continue\n",
    "\n",
    "        layer_type = type(module).__name__\n",
    "        layer_config = {\"type\": layer_type}\n",
    "\n",
    "        if isinstance(module, Conv1d):\n",
    "            layer_config.update({\n",
    "                \"in_channels\": module.in_channels,\n",
    "                \"out_channels\": module.out_channels,\n",
    "                \"kernel_size\": module.kernel_size,\n",
    "                \"padding\": module.padding,\n",
    "            })\n",
    "        elif isinstance(module, Linear):\n",
    "            layer_config.update({\n",
    "                \"in_features\": module.in_features,\n",
    "                \"out_features\": module.out_features,\n",
    "            })\n",
    "        elif isinstance(module, LSTM):\n",
    "            layer_config.update({\n",
    "                \"input_size\": module.input_size,\n",
    "                \"hidden_size\": module.hidden_size,\n",
    "                \"num_layers\": module.num_layers,\n",
    "                \"bidirectional\": module.bidirectional,\n",
    "            })\n",
    "        elif isinstance(module, MaxPool1d):\n",
    "            layer_config.update({\n",
    "                \"kernel_size\": module.kernel_size,\n",
    "                \"stride\": module.stride,\n",
    "            })\n",
    "        elif isinstance(module, Embedding):\n",
    "            layer_config.update({\n",
    "                \"num_embeddings\": module.num_embeddings,\n",
    "                \"embedding_dim\": module.embedding_dim,\n",
    "            })\n",
    "\n",
    "        config[name] = layer_config\n",
    "\n",
    "    return config\n",
    "\n",
    "def wandb_config_entry(model: Module, name: str, train_params: dict, entity: str, project: str) -> wandb.init:\n",
    "    config = {}\n",
    "    config['architecture'] = extract_model_config(model)\n",
    "    config['training'] = train_params\n",
    "    return wandb.init(name = name, project = project, entity = entity, config = config)\n",
    "\n",
    "def train_test_datasets(X, y, user_ids, train_proportion, batch_size, normalize, device = device):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=train_proportion, random_state=MY_SEED)\n",
    "    indices = np.arange(len(y))\n",
    "    train_idx, val_idx = next(sss.split(indices, y.numpy()))\n",
    "    \n",
    "    \n",
    "    dataset = TensorDataset(X, y, user_ids)\n",
    "    \n",
    "    train_dataset, val_dataset = Subset(dataset, train_idx), Subset(dataset, val_idx)\n",
    "    \n",
    "    if normalize:\n",
    "        mean, scale = get_mean_std(X[train_idx])\n",
    "        train_X = normalize_X(X[train_idx], (mean, scale))\n",
    "        val_X = normalize_X(X[val_idx], (mean, scale))\n",
    "        train_dataset = TensorDataset(train_X, y[train_idx], user_ids[train_idx])\n",
    "        val_dataset = TensorDataset(val_X, y[val_idx], user_ids[val_idx])\n",
    "    else:\n",
    "        \n",
    "        mean, scale = None, None\n",
    "        \n",
    "    y_train_split = y[train_idx]\n",
    "    sampler_weights = class_weights[y_train_split.numpy()]\n",
    "    sampler = WeightedRandomSampler(sampler_weights, num_samples=len(sampler_weights))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, train_dataset, val_dataset, val_loader, mean, scale\n",
    "\n",
    "class AdversarialGradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.alpha * grad_output, None\n",
    "\n",
    "def grad_reverse(x, alpha=1.0):\n",
    "    return AdversarialGradReverse.apply(x, alpha)\n",
    "\n",
    "class NewModel(Module):\n",
    "    def __init__(self, num_classes, num_users, user_embedding_dim=16, num_filters=40, num_layers=2, bidirectional=True):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.relu = ReLU()\n",
    "        self.conv1 = Conv1d(in_channels=3, out_channels=num_filters, kernel_size=5, padding='same')\n",
    "        self.conv2 = Conv1d(in_channels=num_filters, out_channels=num_filters, kernel_size=7, padding='same')\n",
    "        self.conv3 = Conv1d(in_channels=num_filters, out_channels=num_filters, kernel_size=9, padding='valid', stride=2)\n",
    "        self.conv4 = Conv1d(in_channels=num_filters, out_channels=num_filters, kernel_size=11, padding='valid', stride=3)\n",
    "        \n",
    "        self.lstm1 = LSTM(num_filters, hidden_size=num_filters, batch_first=True, \n",
    "                          dropout=0.5, num_layers=num_layers, bidirectional=bidirectional)\n",
    "        feature_dim = num_filters * 2 * (2 if bidirectional else 1)    \n",
    "        self.activity_classifier = Sequential(\n",
    "            Linear(feature_dim, num_classes)\n",
    "        )        \n",
    "        self.user_discriminator = Sequential(\n",
    "            Linear(feature_dim, 64),\n",
    "            ReLU(),\n",
    "            Linear(64, num_users + 1)\n",
    "        )\n",
    "        \n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        # x = self.relu(self.conv4(x))\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        avg_pool = torch.mean(x, dim=2)\n",
    "        max_pool, _ = torch.max(x, dim=2)\n",
    "        features = torch.cat((avg_pool, max_pool), dim=1)\n",
    "        return features\n",
    "    \n",
    "    def forward(self, x, user_ids=None, alpha=1.0):\n",
    "        features = self.extract_features(x)\n",
    "        activity_logits = self.activity_classifier(features)\n",
    "        if user_ids is not None:\n",
    "            reversed_features = grad_reverse(features, alpha)\n",
    "            user_logits = self.user_discriminator(reversed_features)\n",
    "            \n",
    "            return activity_logits, user_logits\n",
    "        else:\n",
    "            return activity_logits\n",
    "\n",
    "def train_model(model, train_loader, val_dataset, optimizer, loss_fn, num_epochs, run, alpha_schedule, device = device):\n",
    "    X_val, y_val, user_ids_val = val_dataset[:]\n",
    "    \n",
    "    X_val = X_val.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "    user_ids_val = user_ids_val.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        alpha = alpha_schedule(epoch, num_epochs)\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        activity_loss_sum = 0.0\n",
    "        user_loss_sum = 0.0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for X_batch, y_batch, user_ids_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            user_ids_batch = user_ids_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            activity_logits, user_logits = model(X_batch, user_ids_batch, alpha)\n",
    "            activity_loss = loss_fn(activity_logits, y_batch)\n",
    "            user_loss = F.cross_entropy(user_logits, user_ids_batch)\n",
    "            loss = activity_loss + user_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            activity_loss_sum += activity_loss.item()\n",
    "            user_loss_sum += user_loss.item()\n",
    "            batch_count += 1\n",
    "        avg_loss = total_loss / batch_count\n",
    "        avg_activity_loss = activity_loss_sum / batch_count\n",
    "        avg_user_loss = user_loss_sum / batch_count\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_activity_logits, val_user_logits = model(X_val, user_ids_val, alpha)\n",
    "            val_activity_loss = loss_fn(val_activity_logits, y_val)\n",
    "            val_user_loss = F.cross_entropy(val_user_logits, user_ids_val)\n",
    "            val_loss = val_activity_loss + val_user_loss\n",
    "            _, predicted_activities = torch.max(val_activity_logits, 1)\n",
    "            activity_accuracy = (predicted_activities == y_val).float().mean().item()\n",
    "            _, predicted_users = torch.max(val_user_logits, 1)\n",
    "            user_accuracy = (predicted_users == user_ids_val).float().mean().item()\n",
    "        \n",
    "        predicted_np = predicted_activities.cpu().numpy()\n",
    "        y_val_np = y_val.cpu().numpy()\n",
    "\n",
    "        precision = precision_score(y_val_np, predicted_np, average='weighted')\n",
    "        recall = recall_score(y_val_np, predicted_np, average='weighted')\n",
    "        f1 = f1_score(y_val_np, predicted_np, average='weighted')\n",
    "        epoch_time = time.time() - t\n",
    "        \n",
    "        run.log({\n",
    "            'epoch': epoch,\n",
    "            'alpha': alpha,\n",
    "            'train_loss': avg_loss,\n",
    "            'train_activity_loss': avg_activity_loss,\n",
    "            'train_user_loss': avg_user_loss,\n",
    "            'val_loss': val_loss.item(),\n",
    "            'val_activity_loss': val_activity_loss.item(),\n",
    "            'val_user_loss': val_user_loss.item(),\n",
    "            'activity_accuracy': activity_accuracy,\n",
    "            'user_accuracy': user_accuracy,\n",
    "            'f1_score': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'epoch_time': epoch_time\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss = {avg_loss:.4f}, Val Loss = {val_loss.item():.4f}\")\n",
    "        print(f\"  Activity Acc = {activity_accuracy:.4f}, User Acc = {user_accuracy:.4f} (lower is better)\")\n",
    "        print(f\"  Precision = {precision:.4f}, Recall = {recall:.4f}, F1 Score = {f1:.4f}\")\n",
    "        print(f\"  Alpha = {alpha:.4f}\")\n",
    "\n",
    "def alpha_schedule(epoch, max_epochs):\n",
    "    \"\"\"\n",
    "    Gradually increase alpha (adversarial pressure)\n",
    "    \"\"\"\n",
    "    return min(1.0, epoch / (max_epochs * 0.5))\n",
    "\n",
    "def new_model_run(model, name, train_params, entity=WANDB_ENTITY, project=WANDB_PROJECT, \n",
    "                             X=None, y=None, user_ids=None, optimizer_class=RMSprop, \n",
    "                             loss_fn=None, show_conf_matrix=False, normalize=False, alpha=0.005):\n",
    "    \n",
    "    run = wandb_config_entry(model, name, train_params, entity, project)\n",
    "    train_proportion = train_params['train_proportion']\n",
    "    batch_size = train_params['batch_size']\n",
    "    lr = train_params['lr']\n",
    "    num_epochs = train_params['num_epochs']\n",
    "    optimizer = optimizer_class(params=model.parameters(), lr=lr, weight_decay=alpha)\n",
    "    \n",
    "    train_loader, train_dataset, val_dataset, val_loader, mean, scale = train_test_datasets(\n",
    "        X, y, user_ids, train_proportion, batch_size, normalize=normalize\n",
    "    )\n",
    "\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_dataset=val_dataset,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        num_epochs=num_epochs,\n",
    "        run=run,\n",
    "        alpha_schedule=alpha_schedule\n",
    "    )\n",
    "    \n",
    "    run.finish()\n",
    "    \n",
    "    if show_conf_matrix:\n",
    "        conf_matrix(model, val_loader)\n",
    "    \n",
    "    return mean, scale\n",
    "    \n",
    "def conf_matrix(model, val_loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, user_ids_batch in val_loader:\n",
    "            outputs, _ = model(X_batch, user_ids_batch, alpha=0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y_batch.cpu())\n",
    "            \n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "X_train = get_X_signal(df_train).to(device)\n",
    "X_test = get_X_signal(df_test).to(device)\n",
    "\n",
    "user_ids_train = extract_user_ids(df_train)\n",
    "user_ids_test = extract_user_ids(df_test)\n",
    "NUM_USERS = int(user_ids_train.max().item())\n",
    "\n",
    "scale_mean, scale_std = get_mean_std(X_train)\n",
    "\n",
    "labels_train = df_train['activity']\n",
    "le = LabelEncoder()\n",
    "y_train = Tensor(le.fit_transform(labels_train)).long()\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "class_counts = np.bincount(y_train, minlength=NUM_CLASSES)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights * (len(y_train) / np.sum(class_weights*class_counts))\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "loss_fn = CrossEntropyLoss(weight=class_weights.to(device))\n",
    "\n",
    "normalize = False\n",
    "bidirectional = True\n",
    "num_filters = 64\n",
    "num_layers = 1\n",
    "alpha = 0.005\n",
    "user_embedding_dim = 64\n",
    "\n",
    "model = NewModel(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    num_users=NUM_USERS,\n",
    "    user_embedding_dim=user_embedding_dim,\n",
    "    num_filters=num_filters,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "name = 'CNN-3-BiLSTM-1_userembed_150epoch_64_64'\n",
    "train_params = {\n",
    "    'train_proportion': 0.8,\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.001,\n",
    "    'num_epochs': 150\n",
    "}\n",
    "\n",
    "mean, scale = new_model_run(\n",
    "    model=model,\n",
    "    name=name,\n",
    "    train_params=train_params,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    user_ids=user_ids_train,\n",
    "    optimizer_class=Adam,\n",
    "    loss_fn=loss_fn,\n",
    "    normalize=normalize,\n",
    "    alpha=alpha\n",
    ")\n",
    "\n",
    "def predict_on_test(model, X_test, batch_size=train_params['batch_size']):\n",
    "    model.eval()\n",
    "    test_dataset = TensorDataset(X_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (X_batch,) in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds)\n",
    "            \n",
    "    return torch.cat(all_preds).to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b98b24",
   "metadata": {},
   "source": [
    "# Output Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = predict_on_test(model, X_test)\n",
    "df_submission = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'predicted': le.inverse_transform(test_predictions)\n",
    "})\n",
    "\n",
    "df_submission=pd.concat([\n",
    "    df_submission,\n",
    "    pd.read_csv(path + '/predictions_allzero.csv')\n",
    "]).to_csv(f'{predictions_path}/{name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
